Projet de Ville Intelligente â€“ Smart City IoT
Ce projet simule une ville intelligente (Smart City) qui centralise les donnÃ©es gÃ©nÃ©rÃ©es par plusieurs capteurs IoT simulÃ©s. Il permet de suivre en temps rÃ©el les mesures suivantes :

ğŸš— Le trafic routier

âš¡ La consommation dâ€™Ã©nergie

ğŸ’§ La consommation dâ€™eau

Les donnÃ©es sont gÃ©nÃ©rÃ©es par des producteurs Kafka, stockÃ©es dans InfluxDB via un consumer Kafka, puis visualisÃ©es grÃ¢ce Ã  Grafana sur des tableaux de bord dynamiques.

ğŸ“Œ Objectifs
Centraliser les donnÃ©es de capteurs simulÃ©s

Utiliser Kafka pour gÃ©rer les flux de donnÃ©es

Stocker les donnÃ©es dans InfluxDB

Visualiser les donnÃ©es avec Grafana

ğŸ§± Architecture du projet
mermaid
graph TD
  A[Capteurs simulÃ©s<br>(Producers Kafka)] -->|Envoi donnÃ©es| B[Topics Kafka]
  B --> C[Consumer Kafka]
  C -->|Insertion| D[InfluxDB]
  D --> E[Tableaux de bord<br>Grafana]
ğŸ› ï¸ Technologies utilisÃ©es
Apache Kafka & Zookeeper : pour le streaming des donnÃ©es

InfluxDB : base de donnÃ©es de sÃ©ries temporelles

Grafana : visualisation des donnÃ©es

Java (Maven) : pour lâ€™implÃ©mentation des producteurs et du consommateur

Docker Compose : pour orchestrer les conteneurs

ğŸ“ Structure du projet
bash
smart-city-project/
â”‚
â”œâ”€â”€ docker-compose.yml         # DÃ©ploiement de Kafka, InfluxDB, Grafana
â”œâ”€â”€ producer/                  # Code des producteurs Kafka (simulateurs de capteurs)
â”œâ”€â”€ consumer/                  # Code du consommateur Kafka
â”œâ”€â”€ pom.xml                    # DÃ©pendances Maven
â””â”€â”€ README.md                  # Fichier d'explication du projet
ğŸš€ Lancer le projet
1. Cloner le projet
bash
git clone https://github.com/ton-utilisateur/smart-city-project.git
cd smart-city-project
2. DÃ©marrer les services avec Docker Compose
bash
docker-compose up -d
Cela lance :

Zookeeper (nÃ©cessaire Ã  Kafka)

Kafka

InfluxDB

Grafana

3. Installer les dÃ©pendances Java
Dans le dossier du projet :

bash
mvn clean install
4. ExÃ©cuter les producteurs et le consommateur
ExÃ©cuter les producteurs qui simulent les capteurs :

bash
java -jar producer/target/producer.jar
ExÃ©cuter le consommateur Kafka :

bash
java -jar consumer/target/consumer.jar
Tu verras dans le terminal :

La gÃ©nÃ©ration des donnÃ©es pour les 3 capteurs

Le consommateur qui lit et insÃ¨re dans InfluxDB

ğŸ“Š AccÃ©der Ã  Grafana
Ouvre Grafana via http://localhost:3000

Connecte-toi avec les identifiants par dÃ©faut :

Username: admin

Password: admin

Ajoute une data source InfluxDB

CrÃ©e des tableaux de bord pour visualiser :

Le trafic

La consommation dâ€™Ã©nergie

La consommation dâ€™eau

ğŸ“¦ Kafka â€“ Topics utilisÃ©s
Les producteurs envoient les donnÃ©es dans les topics suivants :

traffic-sensor

energy-sensor

water-sensor

ğŸ“š Exemple de donnÃ©es gÃ©nÃ©rÃ©es
json
{
  "sensorId": "sensor-1",
  "type": "energy",
  "value": 56.2,
  "timestamp": "2025-05-22T10:21:00Z"
}
âœ… Ã€ faire
 Simuler des capteurs

 Connecter Kafka Ã  InfluxDB

 Visualiser les donnÃ©es sur Grafana

 Ajouter une interface utilisateur Web (optionnel)

 Ajouter lâ€™authentification Grafana et sÃ©curiser les accÃ¨s

ğŸ“„ Licence
Ce projet est sous licence MIT. Tu peux lâ€™utiliser, le modifier et le distribuer librement.
